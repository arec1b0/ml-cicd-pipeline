{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03 - Evaluation, Model-Gating & Smoke Tests\n",
        "Purpose:\n",
        " - evaluate the model and compute gating decision\n",
        " - provide smoke test code that will be used by CI to validate a deployed API\n",
        "\n",
        "This notebook contains:\n",
        " - metric computation used for gating (example: val_accuracy threshold)\n",
        " - example of hitting the running FastAPI service and asserting a valid response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import json\n",
        "import joblib\n",
        "import logging\n",
        "import requests\n",
        "from typing import Dict\n",
        "\n",
        "ROOT = Path.cwd()\n",
        "MODEL_DIR = ROOT / \"model_registry\"\n",
        "logging.basicConfig(level=logging.INFO)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.1 — Compute gating decision locally\n",
        "Replace threshold rules with your production gating policy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_gating(meta_path: str, threshold: float=0.70) -> Dict:\n",
        "    \"\"\"\n",
        "    Read model metadata and compute whether the model passes gating rules.\n",
        "    Returns a dict with pass/fail and reason(s).\n",
        "    \"\"\"\n",
        "    meta = json.loads(Path(meta_path).read_text())\n",
        "    acc = float(meta.get(\"val_accuracy\", 0.0))\n",
        "    passed = acc >= threshold\n",
        "    return {\"passed\": passed, \"val_accuracy\": acc, \"threshold\": threshold, \"meta\": meta}\n",
        "\n",
        "# example: pick latest meta\n",
        "meta_files = list(MODEL_DIR.glob(\"*.meta.json\"))\n",
        "meta_files.sort(key=lambda p: p.stat().st_mtime, reverse=True)\n",
        "if not meta_files:\n",
        "    raise SystemExit(\"No model metadata files found. Run training notebook first.\")\n",
        "result = compute_gating(str(meta_files[0]), threshold=0.70)\n",
        "result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.2 — Smoke test for deployed service\n",
        "This is a CI-friendly smoke test that:\n",
        " - posts a sample payload to /predict\n",
        " - asserts 200 and valid JSON with `predictions` key\n",
        "This code can be used as pytest test or as a GitHub Actions step.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def smoke_test_predict(endpoint: str = \"http://localhost:8000/predict\", sample_payload=None, timeout=5):\n",
        "    \"\"\"\n",
        "    Run a basic smoke test against inference API.\n",
        "    Returns: dict(result, status_code, body)\n",
        "    \"\"\"\n",
        "    if sample_payload is None:\n",
        "        sample_payload = {\"features\": [[5.1, 3.5, 1.4, 0.2]]}\n",
        "    try:\n",
        "        r = requests.post(endpoint, json=sample_payload, timeout=timeout)\n",
        "        r.raise_for_status()\n",
        "        body = r.json()\n",
        "        ok = isinstance(body, dict) and \"predictions\" in body\n",
        "        return {\"ok\": ok, \"status_code\": r.status_code, \"body\": body}\n",
        "    except Exception as exc:\n",
        "        return {\"ok\": False, \"error\": str(exc)}\n",
        "\n",
        "# Example run (CI will point endpoint to deployed service)\n",
        "print(smoke_test_predict(\"http://127.0.0.1:8000/predict\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.3 — Example: integrate gating & smoke test in CI\n",
        "Pseudocode for CI job:\n",
        "\n",
        " - Run training job -> produces model artifact and meta\n",
        " - compute_gating(meta) -> if pass then deploy canary\n",
        " - after canary deployed, run smoke_test_predict against canary endpoint\n",
        " - if smoke ok and metrics (from prometheus) pass, promote; else rollback\n",
        "\n",
        "End of notebook 03.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
